## Directory Structure
# - pdf_pipeline
#    - main.py
#    - api
#        - upload_pdf.py
#    - processing
#        - extract_text.py
#        - chunk_text.py
#    - embeddings
#        - generate_embeddings.py
#    - vector_store
#        - faiss_store.py
#        - pinecone_store.py
#    - README.md

# Create main.py
# This file integrates all modules and serves as an entry point for the application.

### main.py ###
from api.upload_pdf import upload_pdf
from processing.extract_text import extract_text_from_pdf
from processing.chunk_text import chunk_text
from embeddings.generate_embeddings import get_embeddings
from vector_store.faiss_store import create_faiss_index
from vector_store.pinecone_store import store_vectors_pinecone

# Example flow to demonstrate integration
file_path = "example.pdf"
upload_pdf(file_path)
extracted_text = extract_text_from_pdf(file_path)
chunks = chunk_text(extracted_text)
embeddings = [get_embeddings(chunk) for chunk in chunks]

# Store locally in FAISS
create_faiss_index(embeddings)
# Store on Pinecone
index_name = "pdf_vectors"
ids = [f"chunk_{i}" for i in range(len(chunks))]
store_vectors_pinecone(index_name, embeddings, ids)

print("Process completed.")

### api/upload_pdf.py ###
from fastapi import FastAPI, File, UploadFile, HTTPException
import os
app = FastAPI()
@app.post("/upload/")
async def upload_pdf(file: UploadFile = File(...)):
    if file.content_type != "application/pdf":
        raise HTTPException(status_code=400, detail="File must be a PDF")

    file_path = f"./uploaded_files/{file.filename}"
    os.makedirs("./uploaded_files", exist_ok=True)

    with open(file_path, "wb") as f:
        f.write(await file.read())

    return {"message": "File uploaded successfully", "file_path": file_path}

### processing/extract_text.py ###
from PyPDF2 import PdfReader
def extract_text_from_pdf(file_path):
    try:
        reader = PdfReader(file_path)
        text = ""
        for page in reader.pages:
            text += page.extract_text() or ""
        return text.strip()
    except Exception as e:
        return f"Error extracting text: {e}"

### processing/chunk_text.py ###
def chunk_text(text, chunk_size=500, overlap=100):
    words = text.split()
    chunks = []
    for i in range(0, len(words), chunk_size - overlap):
        chunk = " ".join(words[i:i + chunk_size])
        chunks.append(chunk)
    return chunks

### embeddings/generate_embeddings.py ###
import openai
openai.api_key = "a19d1436011598aa166243453adcb2eb7045e5dce622b0870f59184dcc7f4470"

def get_embeddings(chunk):
    try:
        response = openai.Embedding.create(
            input=chunk,
            model="text-embedding-ada-002"
        )
        return response['data'][0]['embedding']
    except Exception as e:
        return f"Error generating embedding: {e}"

### vector_store/faiss_store.py ###
import faiss
import numpy as n
def create_faiss_index(embeddings):
    dimension = len(embeddings[0])
    index = faiss.IndexFlatL2(dimension)
    index.add(np.array(embeddings))
    faiss.write_index(index, "faiss_index.index")
    return index
### vector_store/pinecone_store.py ###
import pinecone
pinecone.init(api_key="a19d1436011598aa166243453adcb2eb7045e5dce622b0870f59184dcc7f4470", environment="us-west1-gcp")
def store_vectors_pinecone(index_name, embeddings, ids):
    index = pinecone.Index(index_name)
    vectors = [(str(ids[i]), embeddings[i]) for i in range(len(embeddings))]
    index.upsert(vectors=vectors)
